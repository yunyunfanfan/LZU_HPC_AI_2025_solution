## **一、赛题背景与目标**

近年来，大语言模型（Large Language Models, LLMs）在自然语言处理领域取得了显著进展，广泛应用于生成、理解、推理等任务。然而，其巨大的计算开销已成为制约实际部署与高效迭代的关键瓶颈。在推理阶段，低延迟、高吞吐的需求对系统性能提出严苛要求；在微调阶段，高昂的显存占用与训练成本限制了模型快速适配下游任务的能力。因此，极需从算法、框架、硬件协同等多维度探索高效的加速优化技术。

本赛题旨在考察参赛者在大语言模型**推理加速**与**微调加速**两个方向上的系统性优化能力，重点评估其对现代深度学习系统栈的理解深度、工程实现能力以及软硬件协同优化的综合素养。

参赛者需围绕“**推理加速优化**”和“**微调加速优化**”两个方向开展工作，**两项任务均须完成**。通过自主设计并实施优化方案，提交一份详实的技术报告及配套材料，全面展示其在模型部署、计算图优化、分布式训练、硬件适配等方面的技术积累与实践能力。

---

## **二、任务要求**

### 1. 提交内容与方式

- 提交一个压缩包，包含以下内容：
  - **技术报告（推荐PDF格式）**：需系统阐述所采用的优化方法、实验设计、结果分析，结构应包括但不限于：基线构建、优化策略、实验设置、性能对比分析。
  - **补充材料**：包括核心代码片段、运行日志、性能监控数据（如显存占用、延迟、吞吐量）等，用于佐证报告中所述结论。
  - **提交时间与方式**: 在**12月15日23:59之前**(请认真阅读时间, 不与本次比赛一致) 将报告和补充材料打包压缩, 提交至`hpcclass@lzu.edu.cn`, 邮件主题和压缩文件命名格式为"AI-LZU-姓名-联系方式"。
> **特别要求**：报告中必须提供基于原始 PyTorch 实现的基准测试代码（即未加优化的标准实现），以便评审人员评估加速效果的真实性，防止通过弱化基线人为夸大加速比。

---

### 2. 硬件平台

- **硬件类型不限**：允许使用 CPU、GPU、NPU 或其他异构计算设备；
- **硬件资源**：我们提供一定价值的算力券, 参赛者也可从下面途径自行获取计算资源: Kaggle Notebook、Google Colab Pro、云平台实例(阿里云 PAI、华为云 ModelArts、AWS EC2等)、实验室服务器等；
- **硬件信息标注**：报告中须明确注明所用设备型号（如 NVIDIA A100-80GB、H800、Ascend 910B 等）；
- **加分项**：
  - 使用多卡或多机并行环境进行优化；
  - 利用高端加速卡或跨多种硬件架构（如 GPU+CPU）实现协同优化。

---

### 3. 赛道任务说明

#### （1）**推理加速优化**

参赛者可任选以下**一种推理场景**进行优化，并在报告中明确声明所选场景：

- **低并发场景**：设定 `batch_size = 1`，对至少包含 **500条查询** 的数据集完成推理任务；
- **高并发场景**：不限 `batch_size`，对至少包含 **2000条查询** 的数据集完成推理任务。

> **精度要求**：若优化方法可能导致输出质量下降（如量化、剪枝），需在标准数学或逻辑推理 benchmark（如 GSM8K、MATH）上测试并报告原始模型与优化后模型的准确率对比。

> **主要评估指标**：**加速比**（Speedup Ratio）或**吞吐量提升**（Throughput Increase），以及可能的**精度损失**。

#### （2）**微调加速优化**

- 使用选定模型在至少 **4000条样本** 的数据集上完成 **不少于2个epoch** 的微调任务；
- 若所用优化方法已知会影响最终训练效果（如 LoRA 在某些任务上性能略低于全参数微调），需在报告中引用方法来源文献（论文、技术博客、GitHub Issue 等）说明影响程度，**无需自行重新评测下游任务性能**；
- **主要评估指标**：**训练速度加速比**（Wall-clock Time Reduction）与**显存峰值占用变化**（Peak Memory Usage）。

---

### 4. 模型选择

- 模型参数规模不限；
- 使用更大参数量模型将体现更强的工程驾驭能力，**酌情加分**。

---

### 5. 数据集选择

- 建议选用公开、标准的数据集，例如：`ultrachat-200k`、`gsm8k` 等；
- 若优化方法对数据分布敏感（如 PagedAttention 在长序列差异大时优势明显），需在报告中说明其适用条件与加速效果的相关性。

---

### 6. 优化方法

允许采用任何合法且有效的加速手段，包括但不限于：

| 方向         | 可选技术                                                     |
| ------------ | ------------------------------------------------------------ |
| **推理优化** | 量化（INT4/FP8/AWQ/GPTQ）、KV Cache 优化、PagedAttention、投机解码（Speculative Decoding）、模型剪枝、ONNX Runtime、TensorRT、vLLM、DeepSpeed Inference |
| **微调优化** | LoRA/LoRA+、QLoRA、ZeRO（Stage 2/3）、FSDP、梯度检查点（Gradient Checkpointing) |

**强制要求**：

- 所有优化方案必须与**相同硬件条件下**的 **标准 PyTorch 基线** 进行横向对比；
- 报告中需清晰列出以下关键指标：
  - 加速比（或吞吐量提升）
  - 显存峰值变化（微调加速优化赛道）
  - 精度损失（如有）
- 必须提供**核心优化代码片段** ，以增强技术论证的可信度。

---

### 7. 能力体现层级（评分参考）

本赛题不设硬性性能门槛，重点考察技术理解深度与工程实现能力。评分将参考以下能力层级：

| 层级                                    | 能力描述                                                     |
| --------------------------------------- | ------------------------------------------------------------ |
| **Level 3：基本掌握**                   | 能独立完成端到端优化流程，提供完整可复现的代码与实验数据，给出明确的加速比。 |
| **Level 2：有一定了解，可在指导下掌握** | 提供清晰的技术说明与演示代码（demo），能解释原理与适用场景。 |
| **Level 1：仅了解理念**                 | 文字性介绍某项技术的思想与潜在价值，无代码实现。             |

> 注：仅完成初步实现但覆盖广泛技术点者，得分低于在单一方向深入探索者。

---

### 8. 鼓励拓展内容（加分项）

- 对特定硬件架构（如 Tensor Core、NPU 向量单元）的特性理解与针对性优化；
- 使用性能分析工具（如 **Nsight Systems**、**PyTorch Profiler**）定位系统瓶颈并指导优化；
- 实现 CPU-GPU 协同流水线优化，减少数据搬运开销；
- 探索多级优化组合策略的协同效应。

---

## **三、评分原则**

本赛题坚持“重过程、重思维、重潜力”的评价导向，**不以单一性能指标为唯一评判标准**。最终评分将综合考量以下维度：

- **技术深度**：对优化机制的理解是否透彻，能否解释“为何有效”；
- **工程能力**：代码质量、实验设计合理性、结果可复现性；
- **系统思维**：是否具备软硬件协同视角，能否识别并解决关键瓶颈；
- **分析逻辑**：问题拆解是否清晰，数据支撑是否充分；
- **创新性与探索精神**：是否提出新颖思路、尝试前沿技术或发现非常规现象。

> **特别说明**：即使某些优化尚未完全实现，只要能提出合理的技术路径、清晰的分析框架或有价值的洞察，也将视为有效贡献，予以认可与鼓励。

> **重要提示**：**在任一赛道上实现深度优化的方案，其评分将高于在两个赛道上均仅完成浅层尝试的方案**。

---

## **四、建议与提示**


1. **循序渐进，迭代优化**  
   建议从中小规模模型（如 1B~3B）入手，在单卡环境下验证基础技术（如 LoRA、INT4 量化），再逐步扩展至多卡并行、复杂组合优化。

2. **重视基线构建**  
   基准实现应基于标准库（如 Hugging Face Transformers）构建，避免因基线效率过低导致“虚假加速”。建议统一使用 `transformers` + `AutoModelForCausalLM` 作为起点。

3. **善用主流工具链**  
   推荐使用以下成熟框架提升开发效率：
   - 模型加载与推理：`transformers`, `vLLM`, `TGI`
   - 参数高效微调：`peft`, `bitsandbytes`
   - 分布式训练：`DeepSpeed`, `FSDP`, `accelerate`
   - 性能分析：`torch.profiler`, `Nsight Systems`

---

## **五、结语**

本赛题不仅是一次技术能力的检验，更是通向高性能 AI 系统研发的入门钥匙。我们期待看到每一位参与者在探索过程中展现出的热情、创造力与扎实功底。无论当前水平如何，只要你愿意深入思考、勇于实践，就有机会脱颖而出！
